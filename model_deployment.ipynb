{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b5723f5-355d-4fe0-9b8b-ca59dd6d3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a7d5434-9cfa-48c1-aaec-c768018ac1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pipeline/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model.pickle', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1ec1b3-bb2d-4b29-89df-0affd0df4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = np.array([\n",
    "    [1, 2, 3, 4]  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476c967d-ccf2-4ded-b0e4-d65c3d19c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edffc1d4-6158-401e-ad25-7cc29e783dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = np.array([\n",
    "    [1, 2, 3, 4],  \n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "\n",
    "y_test = np.array([0, 1, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc4b1d7-46f1-4694-9ed2-5c634b1da2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4203c595-0958-47f4-8bb0-61e50733a753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.7777777777777777\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.67      0.83      0.56         3\n",
      "weighted avg       1.00      0.67      0.78         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, predictions, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, predictions, average='weighted', zero_division=1)\n",
    "report = classification_report(y_test, predictions, zero_division=1)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d159f275-3a7a-4bc8-99a0-b8108cbec160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230b3cc37efb476393dc084ee40a335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Feature 1', max=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0054b81f3c4683866eed527f42e461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Feature 2', max=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675c41022bee4f41b7c1f0e4477ae0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Feature 3', max=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96ac023ae0e41f7bf4ecdf3fe63e611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Feature 4', max=10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649f240a738746edb22e80048c36d293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f88f9946084aeeaaf16190333c585d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_1 = widgets.FloatSlider(description='Feature 1', min=0, max=10, step=0.1)\n",
    "feature_2 = widgets.FloatSlider(description='Feature 2', min=0, max=10, step=0.1)\n",
    "feature_3 = widgets.FloatSlider(description='Feature 3', min=0, max=10, step=0.1)\n",
    "feature_4 = widgets.FloatSlider(description='Feature 4', min=0, max=10, step=0.1)\n",
    "predict_button = widgets.Button(description='Predict')\n",
    "\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def make_prediction(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        features = np.array([[feature_1.value, feature_2.value, feature_3.value, feature_4.value]])\n",
    "        prediction = model.predict(features)\n",
    "        print(f'Prediction: {prediction[0]}')\n",
    "\n",
    "\n",
    "predict_button.on_click(make_prediction)\n",
    "\n",
    "\n",
    "display(feature_1, feature_2, feature_3, feature_4, predict_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf148e7-6249-4d56-9233-01abb8254577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
